{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c0959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024696e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\envs\\idp\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7990b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\envs\\idp\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Hp\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d415f9beac5440b194a0d02a8429c144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556be651ed4242c68acd1046b342f0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbeab122f604c19ac00f8f33cf070c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time\n",
      "Generated Text: Once upon a time, the world was a place of great beauty and great danger. The world of the gods was the place where the great gods were born, and where they were to live.\n",
      "\n",
      "The world that was created was not the same as the one that is now. It was an endless, endless world. And the Gods were not born of nothing. They were created of a single, single thing. That was why the universe was so beautiful. Because the cosmos was made of two\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_text(prompt, max_length=100):\n",
    "    model_name = 'gpt2'  # You can use 'gpt2-medium', 'gpt2-large', etc.\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Once upon a time\"\n",
    "    generated_text = generate_text(prompt)\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Generated Text:\", generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
